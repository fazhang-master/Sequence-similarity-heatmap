{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4c2e90-dacf-46f0-95f4-63062056d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangfa/miniconda3/envs/base2/lib/python3.10/site-packages/Bio/Application/__init__.py:39: BiopythonDeprecationWarning: The Bio.Application modules and modules relying on it have been deprecated.\n",
      "\n",
      "Due to the on going maintenance burden of keeping command line application\n",
      "wrappers up to date, we have decided to deprecate and eventually remove these\n",
      "modules.\n",
      "\n",
      "We instead now recommend building your command line and invoking it directly\n",
      "with the subprocess module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.Blast.Applications import NcbiblastpCommandline\n",
    "from Bio.Blast import NCBIXML\n",
    "import glob\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a97306-eba0-44a0-921f-9735a87c0cdc",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6fafe4-c4ef-4252-b467-c03dfc154eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExcel(file_path, sheet_name):\n",
    "    ganmeiNew1 = pd.read_excel(file_path,sheet_name=f\"{sheet_name}\")\n",
    "    \n",
    "    print(ganmeiNew1[:5])\n",
    "    return ganmeiNew1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3c01aa-532f-46ad-a8be-80f4e6bbb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataRest(df):\n",
    "    # 将第一行数据设为列名\n",
    "    df.columns = df.iloc[0]\n",
    "\n",
    "    # 删除原来的第一行，并重置索引\n",
    "    df = df.drop(0).reset_index(drop=True)\n",
    "\n",
    "    print(df[:5])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13aced64-e0a0-451e-b193-535d3883348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClean(df,outpath):\n",
    "    \n",
    "    # 清洗 species 列：去除括号及后续内容（如 \"Ectocarpus siliculosus（褐藻）\" → \"Ectocarpus siliculosus\"）\n",
    "    df[\"species\"] = df[\"species\"].str.split(r\"[（(]\").str[0].str.strip()\n",
    "\n",
    "    # 合并 species 和 name 列，生成新名称，并剔除换行符\n",
    "    df[\"name\"] = (df[\"species\"] + \"_\" + df[\"name\"]).str.replace(r'[\\n\\r]', '', regex=True)\n",
    "\n",
    "    # 提取需要的字段并重命名列\n",
    "    result = df[[\"name\", \"Aa sequences\"]].rename(columns={\"Aa sequences\": \"seq\"})\n",
    "\n",
    "    # 剔除 seq 中的换行符（\\n 或 \\r）\n",
    "    result[\"seq\"] = result[\"seq\"].str.replace(r'[\\n\\r]', '', regex=True)\n",
    "\n",
    "    # 基于 name 和 seq 去重（保留第一条重复记录）\n",
    "    result = result.drop_duplicates(subset=[\"name\", \"seq\"], keep=\"first\")\n",
    "\n",
    "    # 转换为字典列表格式\n",
    "    json_data = result.to_dict(orient=\"records\")\n",
    "\n",
    "    # 保存为 JSON 文件（格式化缩进）\n",
    "    with open(outpath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"JSON 文件已保存成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da04afd-a512-4140-9710-afd7313efd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_name(name):\n",
    "    \"\"\"替换希腊字母为英文单词并移除其他非ASCII字符\"\"\"\n",
    "    replacements = {\n",
    "        'α': 'alpha',\n",
    "        'β': 'beta',\n",
    "        'γ': 'gamma',\n",
    "    }\n",
    "    \n",
    "    # 替换希腊字母\n",
    "    for greek, eng in replacements.items():\n",
    "        name = name.replace(greek, eng)\n",
    "    \n",
    "    # 移除其他非ASCII字符\n",
    "    name = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb87025c-4034-45b3-bf87-c628b7849f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blast_database(fasta_path, gene_name):\n",
    "    \"\"\"创建BLAST数据库并处理异常\"\"\"\n",
    "    try:\n",
    "        db_path = f\"temp_{gene_name}_db\"\n",
    "        cmd = f\"makeblastdb -in {fasta_path} -dbtype prot -out {db_path}\"\n",
    "        subprocess.run(cmd, check=True, shell=True)\n",
    "        return db_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error creating BLAST database: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d408792-7c70-4fe3-950e-611cffd7191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blast_all_vs_all(records, output_dir):\n",
    "    \"\"\"执行全基因组两两BLAST比对\"\"\"\n",
    "    # 准备临时文件（清洗名称）\n",
    "    all_sequences = []\n",
    "    for rec in records:\n",
    "        sanitized_name = sanitize_name(rec['name'])\n",
    "        all_sequences.append(f\">{sanitized_name}\\n{rec['seq']}\")\n",
    "    \n",
    "    with open(\"temp_all.fasta\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(all_sequences))\n",
    "    \n",
    "    # 创建BLAST数据库\n",
    "    db_path = create_blast_database(\"temp_all.fasta\", \"all\")\n",
    "    \n",
    "    # 执行BLASTP\n",
    "    blast_cline = NcbiblastpCommandline(\n",
    "        query=\"temp_all.fasta\",\n",
    "        db=db_path,\n",
    "        outfmt=5,\n",
    "        evalue=10,\n",
    "        out=os.path.join(output_dir, \"blast_results.xml\")\n",
    "    )\n",
    "    stdout, stderr = blast_cline()\n",
    "    \n",
    "    return os.path.join(output_dir, \"blast_results.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "229a4ff9-5de0-4d93-8b20-2e6eba903519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_blast_results(xml_path, original_records):\n",
    "    \"\"\"解析BLAST结果并构建相似度矩阵\"\"\"\n",
    "    # 创建清洗后的名称映射\n",
    "    name_mapping = {sanitize_name(rec['name']): rec['name'] for rec in original_records}\n",
    "    # print(name_mapping)\n",
    "    \n",
    "    # 初始化矩阵\n",
    "    species = [rec['name'] for rec in original_records]\n",
    "    matrix = pd.DataFrame(0.0, index=species, columns=species)\n",
    "    # print(matrix)\n",
    "    np.fill_diagonal(matrix.values, 100.0)\n",
    "    \n",
    "    # 解析XML结果\n",
    "    with open(xml_path) as blast_file:\n",
    "        blast_records = NCBIXML.parse(blast_file)\n",
    "        \n",
    "        for blast_record in blast_records:\n",
    "            query = name_mapping[blast_record.query]  # 转换回原始名称\n",
    "            print(query)\n",
    "            \n",
    "            for alignment in blast_record.alignments:\n",
    "                hit = name_mapping[alignment.hit_def]\n",
    "                # print(hit)\n",
    "                if query == hit:\n",
    "                    continue\n",
    "                \n",
    "                max_sim = 0.0\n",
    "                for hsp in alignment.hsps:\n",
    "                    sim = hsp.identities / alignment.length * 100\n",
    "                    max_sim = max(max_sim, sim)\n",
    "                \n",
    "                matrix.loc[query, hit] = max(max_sim, matrix.loc[query, hit])\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a71ddcb-be43-48e6-96eb-3564b2a4ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(matrix, gene_name, output_dir):\n",
    "    \"\"\"生成符合示例样式的热图\"\"\"\n",
    "    # 动态调整画布尺寸\n",
    "    num_species = len(matrix)\n",
    "    plt.figure(figsize=(num_species*1.4, num_species*1.2))\n",
    "    \n",
    "    # 创建下三角mask\n",
    "    mask = np.tril(np.ones_like(matrix, dtype=bool), k=-1)\n",
    "    \n",
    "    # 生成热图对象\n",
    "    ax = sns.heatmap(\n",
    "        matrix, \n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        annot_kws={\"size\": 16, \"color\": \"black\"},\n",
    "        fmt=\".1f\",\n",
    "        cmap=\"YlGnBu\",\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        linewidths=0.5,\n",
    "        square=True,\n",
    "        cbar_kws={\n",
    "            \"shrink\": 0.8,\n",
    "            \"label\": \"Similarity (%)\",\n",
    "            \"location\": \"left\"\n",
    "        },\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    \n",
    "    # 自定义标签系统\n",
    "    # ----------------- 顶部标签 -----------------\n",
    "    ax.set_xticks(np.arange(len(matrix.columns)) + 0.5)\n",
    "    ax.set_xticklabels(\n",
    "        matrix.columns,\n",
    "        rotation=45,\n",
    "        ha='left',\n",
    "        va='bottom',\n",
    "        rotation_mode='anchor',\n",
    "        fontsize=16,\n",
    "        fontstyle='italic',\n",
    "        position=(0, 1.02)\n",
    "    )\n",
    "    \n",
    "    # ----------------- 右侧标签 -----------------\n",
    "    ax.set_yticks(np.arange(len(matrix.index)) + 0.5)\n",
    "    ax.set_yticklabels(\n",
    "        matrix.index,\n",
    "        rotation=0,\n",
    "        ha='left',\n",
    "        va='center',\n",
    "        fontsize=16,\n",
    "        position=(1.02, 0),\n",
    "        fontstyle='italic'\n",
    "    )\n",
    "    \n",
    "    # ----------------- 样式优化 -----------------\n",
    "    # 隐藏所有坐标轴线\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    # 特别移除左边和底部残余边框\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    # 添加主标题（与示例完全一致）\n",
    "    plt.title(\n",
    "        f\"Sequence Similarity (%)\",\n",
    "        fontsize=20,\n",
    "        pad=320,  # 精确控制标题间距\n",
    "        fontweight='bold',\n",
    "        color='#333333'\n",
    "    )\n",
    "    \n",
    "    # 布局微调\n",
    "    plt.subplots_adjust(\n",
    "        left=0.15,\n",
    "        right=0.85,\n",
    "        top=0.85,  # 为标题留出空间\n",
    "        bottom=0.1\n",
    "    )\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.savefig(\n",
    "        f\"{output_dir}/{gene_name}_heatmap.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches='tight',\n",
    "        facecolor='white'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3744e380-97ce-4518-8a2b-f64a800a7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path, sheet, input_json, output_dir):\n",
    "\n",
    "    # 数据预处理\n",
    "    gamma = readExcel(file_path, sheet)\n",
    "    print(\"*=-\"*80)\n",
    "    gamma = dataRest(gamma)\n",
    "    print(\"*=-\"*80)\n",
    "    os.makedirs(os.path.dirname(input_json), exist_ok=True)\n",
    "    dataClean(gamma, input_json)\n",
    "    print(\"*=-\"*80)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 读取数据\n",
    "    with open(input_json) as f:\n",
    "        records = json.load(f)\n",
    "    try:\n",
    "        # 执行BLAST比对\n",
    "        blast_xml = run_blast_all_vs_all(records, output_dir)\n",
    "    \n",
    "        # 解析结果\n",
    "        similarity_matrix = parse_blast_results(blast_xml, records)\n",
    "    \n",
    "        # 保存原始数据\n",
    "        similarity_matrix.to_csv(os.path.join(output_dir, \"similarity_matrix.csv\"))\n",
    "    \n",
    "        # 生成热图\n",
    "        plot_heatmap(similarity_matrix, 'sheet1' ,output_dir)\n",
    "\n",
    "    finally:\n",
    "        # 清理临时文件\n",
    "        for f in [\"temp_all.fasta\"] + glob.glob(\"temp_all_db*\"):\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)\n",
    "\n",
    "    print(f\"Analysis complete. Result Save Path:{output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce8a117-07d2-4b65-b587-e4c630903ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0          Unnamed: 1  \\\n",
      "0         NaN                name   \n",
      "1         NaN      pasteurii UreC   \n",
      "2         NaN      aerogenes UreC   \n",
      "3         NaN  leguminosarum UreC   \n",
      "4         NaN             pyloriB   \n",
      "\n",
      "                                          Unnamed: 2    Unnamed: 3  \n",
      "0                                       Aa sequences       species  \n",
      "1  MKINRQQYAESYGPTVGDQVRLADTDLWIEVEKDYTTYGDEANFGG...  Sporosarcina  \n",
      "2  MSNISRQAYADMFGPTVGDKVRLADTELWIEVEDDLTTYGEEVKFG...    Klebsiella  \n",
      "3  MPYKISRAAYAGMFGPTTGDKVRLADTELFIEIEKDFTTYGEEVKF...     Rhizobium  \n",
      "4  MKKISRKEYVSMYGPTTGDKVRLGDTDLIAEVEHDYTIYGEELKFG...  Helicobacter  \n",
      "*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-\n",
      "0  NaN                name                                       Aa sequences  \\\n",
      "0  NaN      pasteurii UreC  MKINRQQYAESYGPTVGDQVRLADTDLWIEVEKDYTTYGDEANFGG...   \n",
      "1  NaN      aerogenes UreC  MSNISRQAYADMFGPTVGDKVRLADTELWIEVEDDLTTYGEEVKFG...   \n",
      "2  NaN  leguminosarum UreC  MPYKISRAAYAGMFGPTTGDKVRLADTELFIEIEKDFTTYGEEVKF...   \n",
      "3  NaN             pyloriB  MKKISRKEYVSMYGPTTGDKVRLGDTDLIAEVEHDYTIYGEELKFG...   \n",
      "4  NaN        organii UreC  MPQISRQEYCGLFGPTTGDKIRLGDTDLYIEIEKDLRGYGEESVYG...   \n",
      "\n",
      "0       species  \n",
      "0  Sporosarcina  \n",
      "1    Klebsiella  \n",
      "2     Rhizobium  \n",
      "3  Helicobacter  \n",
      "4    Morganella  \n",
      "*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-\n",
      "JSON 文件已保存成功！\n",
      "*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-\n",
      "\n",
      "\n",
      "Building a new DB, current time: 07/12/2025 16:09:35\n",
      "New DB name:   /Users/zhangfa/Desktop/DUT/宏基因组/脲酶和碳酸酐酶/temp_all_db\n",
      "New DB title:  temp_all.fasta\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 20 sequences in 0.00118184 seconds.\n",
      "\n",
      "\n",
      "Sporosarcina_pasteurii UreC\n",
      "Klebsiella_aerogenes UreC\n",
      "Rhizobium_leguminosarum UreC\n",
      "Helicobacter_pyloriB\n",
      "Morganella_organii UreC\n",
      "Bacillus_subtilis UreC\n",
      "Priestia_egaterium UreC\n",
      "Helicobacter_ustelae UreB\n",
      "Helicobacter_ustelae UreB2\n",
      "Actinobacillus_pleuropneumoniae UreC\n",
      "Bacillus sp._(strain TB-90) UreC\n",
      "Streptococcus_thermophilus UreC\n",
      "Lactobacillus_reuteri UreC\n",
      "Helicobacter_bizzozeronii UreB\n",
      "Helicobacter_hepaticus UreB\n",
      "Campylobacter_sputorum biovar paraureolyticus UreC\n",
      "Corynebacterium_glutamicum UreC\n",
      "Bacillus_paralicheniformis UreC\n",
      "Haloarcula_arismortui UreC\n",
      "Sphingobacterium_thalpophilum UreC\n",
      "Analysis complete. Result Save Path:./analysis/UreC\n"
     ]
    }
   ],
   "source": [
    "# 配置参数\n",
    "file_path = \"./data/UreC.xlsx\"\n",
    "sheet = \"UreC\"\n",
    "input_json = \"./cleanData/UreC.json\"\n",
    "output_dir = \"./analysis/UreC\"\n",
    "main(file_path, sheet, input_json, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
